{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0691735f-25b9-480b-b0f9-69e00a4a2c48",
   "metadata": {},
   "source": [
    "### For Local Files ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93df136e-e621-4300-881b-72b4f9537a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "\n",
    "def check_file_validity(file_path):\n",
    "    \"\"\"\n",
    "    Checks if the txt file is valid:\n",
    "        1. Has valid delimiter.\n",
    "        2. Detects the file encoding.\n",
    "\n",
    "    Args:\n",
    "        1. file_path(str): Path to the file to be validated.\n",
    "\n",
    "    Returns:\n",
    "        1. dict:{\n",
    "                \"error\": str,\n",
    "                \"file_valid\": bool,\n",
    "                \"delimiter\": char,\n",
    "                \"file_encoding\": str,\n",
    "            }\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_path, \"rb\") as byte_file:\n",
    "        file_content = byte_file.read()\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if not lines:\n",
    "        return {\"error\": \"File is empty\", \"file_valid\": False}\n",
    "\n",
    "    delimiter_obj = check_delimiter(file_lines=lines)\n",
    "    if not delimiter_obj.get(\"delimiter_found\"):\n",
    "        return {\"error\": delimiter_obj.get(\"error\"), \"file_valid\": False}\n",
    "\n",
    "    delimiter = delimiter_obj.get(\"delimiter\")\n",
    "    file_encoding = get_file_encoding(file_content=file_content)\n",
    "    return {\n",
    "        \"error\": None,\n",
    "        \"file_valid\": True,\n",
    "        \"delimiter\": delimiter,\n",
    "        \"file_encoding\": file_encoding,\n",
    "    }\n",
    "\n",
    "\n",
    "def check_delimiter(file_lines):\n",
    "    \"\"\"\n",
    "    Checks for a consistent delimiter used in the file\n",
    "\n",
    "    Args:\n",
    "        1. file_lines(list): List of lines read from a file.\n",
    "\n",
    "    Returns:\n",
    "        1. dict:{\n",
    "                \"error\": str,\n",
    "                \"delimiter_found\": bool,\n",
    "                \"column_numbers\": int,\n",
    "                \"delimiter\": char,\n",
    "            }\n",
    "    \"\"\"\n",
    "    valid_delimiters = [\",\", \"#\", \";\", \":\", \"\\t\", \" \", \"|\"]\n",
    "    first_line = file_lines[0]\n",
    "    delimiter_counts = Counter(ch for ch in first_line if ch in valid_delimiters)\n",
    "\n",
    "    if not delimiter_counts:\n",
    "        return {\n",
    "            \"error\": \"Cannot determine a consistent delimiter\",\n",
    "            \"delimiter_found\": False,\n",
    "            \"column_numbers\": None,\n",
    "            \"delimiter\": None,\n",
    "        }\n",
    "\n",
    "    delimiter, _ = delimiter_counts.most_common(1)[0]\n",
    "    column_numbers = len(first_line.split(delimiter))\n",
    "\n",
    "    return {\n",
    "        \"error\": None,\n",
    "        \"delimiter_found\": True,\n",
    "        \"column_numbers\": column_numbers,\n",
    "        \"delimiter\": delimiter,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_file_encoding(file_content):\n",
    "    \"\"\"\n",
    "    Returns file encoding standard.\n",
    "\n",
    "    Args:\n",
    "        1. file_content(bytes): file content read in binary mode.\n",
    "\n",
    "    Returns:\n",
    "        file_encoding(str): Encoding standard used for the file.\n",
    "    \"\"\"\n",
    "    file_encoding = chardet.detect(file_content).get(\"encoding\", \"utf-8\")\n",
    "    return file_encoding\n",
    "\n",
    "\n",
    "def get_dataframe(file_url):\n",
    "    \"\"\"\n",
    "    Gets the pandas dataframe from the validated file\n",
    "\n",
    "    Args:\n",
    "        1. file_path(str): Path to the file.\n",
    "\n",
    "    Returns:\n",
    "        1. dict:{\n",
    "                \"error\": str,\n",
    "                \"file_valid\": bool,\n",
    "                \"dataframe\": pandas.core.frame.DataFrame,\n",
    "            }\n",
    "    \"\"\"\n",
    "    validity_obj = check_file_validity(file_path=file_url)\n",
    "    if not validity_obj.get(\"file_valid\"):\n",
    "        return {\n",
    "            \"error\": validity_obj.get(\"error\"),\n",
    "            \"file_valid\": False,\n",
    "            \"dataframe\": None,\n",
    "        }\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            file_url,\n",
    "            sep=validity_obj.get(\"delimiter\"),\n",
    "            encoding=validity_obj.get(\"file_encoding\"),\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": f\"Failed to read the file: {str(e)}\",\n",
    "            \"file_valid\": False,\n",
    "            \"dataframe\": None,\n",
    "        }\n",
    "\n",
    "    return {\"error\": None, \"file_valid\": True, \"dataframe\": df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b6c2158-6bc2-4b4a-a506-cdac97927e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Row1_Col1</td>\n",
       "      <td>Row1_Col2</td>\n",
       "      <td>Row1_Col4</td>\n",
       "      <td>Row1_Col5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Row2_Col1</td>\n",
       "      <td>Row2_Col2</td>\n",
       "      <td>Row2_Col3</td>\n",
       "      <td>Row2_Col5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Row3_Col1</td>\n",
       "      <td>Row3_Col2</td>\n",
       "      <td>Row3_Col3</td>\n",
       "      <td>Row3_Col4</td>\n",
       "      <td>Row3_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Row4_Col1</td>\n",
       "      <td>Row4_Col2</td>\n",
       "      <td>Row4_Col3</td>\n",
       "      <td>Row4_Col4</td>\n",
       "      <td>Row4_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Row5_Col1</td>\n",
       "      <td>Row5_Col2</td>\n",
       "      <td>Row5_Col3</td>\n",
       "      <td>Row5_Col4</td>\n",
       "      <td>Row5_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Row6_Col1</td>\n",
       "      <td>Row6_Col2</td>\n",
       "      <td>Row6_Col3</td>\n",
       "      <td>Row6_Col4</td>\n",
       "      <td>Row6_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Row7_Col1</td>\n",
       "      <td>Row7_Col2</td>\n",
       "      <td>Row7_Col3</td>\n",
       "      <td>Row7_Col4</td>\n",
       "      <td>Row7_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Row8_Col1</td>\n",
       "      <td>Row8_Col2</td>\n",
       "      <td>Row8_Col3</td>\n",
       "      <td>Row8_Col4</td>\n",
       "      <td>Row8_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Row9_Col1</td>\n",
       "      <td>Row9_Col2</td>\n",
       "      <td>Row9_Col3</td>\n",
       "      <td>Row9_Col4</td>\n",
       "      <td>Row9_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Row10_Col1</td>\n",
       "      <td>Row10_Col2</td>\n",
       "      <td>Row10_Col3</td>\n",
       "      <td>Row10_Col4</td>\n",
       "      <td>Row10_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Row11_Col1</td>\n",
       "      <td>Row11_Col2</td>\n",
       "      <td>Row11_Col3</td>\n",
       "      <td>Row11_Col4</td>\n",
       "      <td>Row11_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Row12_Col1</td>\n",
       "      <td>Row12_Col2</td>\n",
       "      <td>Row12_Col3</td>\n",
       "      <td>Row12_Col4</td>\n",
       "      <td>Row12_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Row13_Col1</td>\n",
       "      <td>Row13_Col2</td>\n",
       "      <td>Row13_Col3</td>\n",
       "      <td>Row13_Col4</td>\n",
       "      <td>Row13_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Row14_Col1</td>\n",
       "      <td>Row14_Col2</td>\n",
       "      <td>Row14_Col3</td>\n",
       "      <td>Row14_Col4</td>\n",
       "      <td>Row14_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Row15_Col1</td>\n",
       "      <td>Row15_Col2</td>\n",
       "      <td>Row15_Col3</td>\n",
       "      <td>Row15_Col4</td>\n",
       "      <td>Row15_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Row16_Col1</td>\n",
       "      <td>Row16_Col2</td>\n",
       "      <td>Row16_Col3</td>\n",
       "      <td>Row16_Col4</td>\n",
       "      <td>Row16_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Row17_Col1</td>\n",
       "      <td>Row17_Col2</td>\n",
       "      <td>Row17_Col3</td>\n",
       "      <td>Row17_Col4</td>\n",
       "      <td>Row17_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Row18_Col1</td>\n",
       "      <td>Row18_Col2</td>\n",
       "      <td>Row18_Col3</td>\n",
       "      <td>Row18_Col4</td>\n",
       "      <td>Row18_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Row19_Col1</td>\n",
       "      <td>Row19_Col2</td>\n",
       "      <td>Row19_Col3</td>\n",
       "      <td>Row19_Col4</td>\n",
       "      <td>Row19_Col5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Row20_Col1</td>\n",
       "      <td>Row20_Col2</td>\n",
       "      <td>Row20_Col3</td>\n",
       "      <td>Row20_Col4</td>\n",
       "      <td>Row20_Col5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Column1     Column2     Column3     Column4     Column5\n",
       "0    Row1_Col1   Row1_Col2   Row1_Col4   Row1_Col5         NaN\n",
       "1    Row2_Col1   Row2_Col2   Row2_Col3   Row2_Col5         NaN\n",
       "2    Row3_Col1   Row3_Col2   Row3_Col3   Row3_Col4   Row3_Col5\n",
       "3    Row4_Col1   Row4_Col2   Row4_Col3   Row4_Col4   Row4_Col5\n",
       "4    Row5_Col1   Row5_Col2   Row5_Col3   Row5_Col4   Row5_Col5\n",
       "5    Row6_Col1   Row6_Col2   Row6_Col3   Row6_Col4   Row6_Col5\n",
       "6    Row7_Col1   Row7_Col2   Row7_Col3   Row7_Col4   Row7_Col5\n",
       "7    Row8_Col1   Row8_Col2   Row8_Col3   Row8_Col4   Row8_Col5\n",
       "8    Row9_Col1   Row9_Col2   Row9_Col3   Row9_Col4   Row9_Col5\n",
       "9   Row10_Col1  Row10_Col2  Row10_Col3  Row10_Col4  Row10_Col5\n",
       "10  Row11_Col1  Row11_Col2  Row11_Col3  Row11_Col4  Row11_Col5\n",
       "11  Row12_Col1  Row12_Col2  Row12_Col3  Row12_Col4  Row12_Col5\n",
       "12  Row13_Col1  Row13_Col2  Row13_Col3  Row13_Col4  Row13_Col5\n",
       "13  Row14_Col1  Row14_Col2  Row14_Col3  Row14_Col4  Row14_Col5\n",
       "14  Row15_Col1  Row15_Col2  Row15_Col3  Row15_Col4  Row15_Col5\n",
       "15  Row16_Col1  Row16_Col2  Row16_Col3  Row16_Col4  Row16_Col5\n",
       "16  Row17_Col1  Row17_Col2  Row17_Col3  Row17_Col4  Row17_Col5\n",
       "17  Row18_Col1  Row18_Col2  Row18_Col3  Row18_Col4  Row18_Col5\n",
       "18  Row19_Col1  Row19_Col2  Row19_Col3  Row19_Col4  Row19_Col5\n",
       "19  Row20_Col1  Row20_Col2  Row20_Col3  Row20_Col4  Row20_Col5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze_file(\"test.txt\")\n",
    "get_dataframe(\"test.txt\").get(\"dataframe\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca52277",
   "metadata": {},
   "source": [
    "### For File URL ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3acbb81d-b03e-41cc-b1b7-fbb4fd762675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import requests\n",
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def check_file_validity(file_url):\n",
    "    \"\"\"\n",
    "    Checks if the txt file is valid:\n",
    "        1. Has valid delimiter.\n",
    "        2. Detects the file encoding.\n",
    "\n",
    "    Args:\n",
    "        1. file_path(str): Path to the file to be validated.\n",
    "\n",
    "    Returns:\n",
    "        1. dict:{\n",
    "                \"error\": str,\n",
    "                \"file_valid\": bool,\n",
    "                \"delimiter\": char,\n",
    "                \"file_encoding\": str,\n",
    "            }\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(file_url)\n",
    "    if response.status_code != 200:\n",
    "        return {\n",
    "            \"error\": f\"Failed to fetch file. Status code: {response.status_code}\",\n",
    "            \"file_valid\": False,\n",
    "        }\n",
    "\n",
    "    content = response.text\n",
    "    lines = content.splitlines()\n",
    "    if not lines:\n",
    "        return {\"error\": \"File is empty\", \"file_valid\": False}\n",
    "\n",
    "    delimiter_obj = check_delimiter(file_lines=lines)\n",
    "    if not delimiter_obj.get(\"delimiter_found\"):\n",
    "        return {\"error\": delimiter_obj.get(\"error\"), \"file_valid\": False}\n",
    "\n",
    "    delimiter = delimiter_obj.get(\"delimiter\")\n",
    "    file_encoding = get_file_encoding(file_content=response.content)\n",
    "    return {\n",
    "        \"error\": None,\n",
    "        \"file_valid\": True,\n",
    "        \"delimiter\": delimiter,\n",
    "        \"file_encoding\": file_encoding,\n",
    "    }\n",
    "\n",
    "\n",
    "def check_delimiter(file_lines):\n",
    "    \"\"\"\n",
    "    Checks for a consistent delimiter used in the file\n",
    "\n",
    "    Args:\n",
    "        1. file_lines(list): List of lines read from a file.\n",
    "\n",
    "    Returns:\n",
    "        1. dict:{\n",
    "                \"error\": str,\n",
    "                \"delimiter_found\": bool,\n",
    "                \"column_numbers\": int,\n",
    "                \"delimiter\": char,\n",
    "            }\n",
    "    \"\"\"\n",
    "    valid_delimiters = [\",\", \"#\", \";\", \":\", \"\\t\", \" \", \"|\"]\n",
    "    first_line = file_lines[0]\n",
    "    delimiter_counts = Counter(ch for ch in first_line if ch in valid_delimiters)\n",
    "\n",
    "    if not delimiter_counts:\n",
    "        return {\n",
    "            \"error\": \"Cannot determine a consistent delimiter\",\n",
    "            \"delimiter_found\": False,\n",
    "            \"column_numbers\": None,\n",
    "            \"delimiter\": None,\n",
    "        }\n",
    "\n",
    "    delimiter, _ = delimiter_counts.most_common(1)[0]\n",
    "    column_numbers = len(first_line.split(delimiter))\n",
    "\n",
    "    return {\n",
    "        \"error\": None,\n",
    "        \"delimiter_found\": True,\n",
    "        \"column_numbers\": column_numbers,\n",
    "        \"delimiter\": delimiter,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_file_encoding(file_content):\n",
    "    \"\"\"\n",
    "    Returns file encoding standard.\n",
    "\n",
    "    Args:\n",
    "        1. file_content(bytes): file content read in binary mode.\n",
    "\n",
    "    Returns:\n",
    "        file_encoding(str): Encoding standard used for the file.\n",
    "    \"\"\"\n",
    "\n",
    "    file_encoding = chardet.detect(file_content).get(\"encoding\", \"utf-8\")\n",
    "    return file_encoding\n",
    "\n",
    "\n",
    "def get_dataframe(file_url):\n",
    "    \"\"\"\n",
    "    Gets the pandas dataframe from the validated file\n",
    "\n",
    "    Args:\n",
    "        1. file_path(str): Path to the file.\n",
    "\n",
    "    Returns:\n",
    "        1. dict:{\n",
    "                \"error\": str,\n",
    "                \"file_valid\": bool,\n",
    "                \"dataframe\": pandas.core.frame.DataFrame,\n",
    "            }\n",
    "    \"\"\"\n",
    "\n",
    "    validity_obj = check_file_validity(file_url=file_url)\n",
    "    if not validity_obj.get(\"file_valid\"):\n",
    "        return {\n",
    "            \"error\": validity_obj.get(\"error\"),\n",
    "            \"file_valid\": False,\n",
    "            \"dataframe\": None,\n",
    "        }\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            file_url,\n",
    "            sep=validity_obj.get(\"delimiter\"),\n",
    "            encoding=validity_obj.get(\"file_encoding\"),\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to read the file: {str(e)}\", \"file_valid\": False}\n",
    "\n",
    "    return {\"error\": None, \"file_valid\": True, \"dataframe\": df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f565c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  location_id                   address_1  address_2  \\\n",
      "0    1            1       2600 Middlefield Road        NaN   \n",
      "1    2            2            24 Second Avenue        NaN   \n",
      "2    3            3            24 Second Avenue        NaN   \n",
      "3    4            4            24 Second Avenue        NaN   \n",
      "4    5            5            24 Second Avenue        NaN   \n",
      "5    6            6           800 Middle Avenue        NaN   \n",
      "6    7            7              500 Arbor Road        NaN   \n",
      "7    8            8           800 Middle Avenue        NaN   \n",
      "8    9            9       2510 Middlefield Road        NaN   \n",
      "9   10           10       1044 Middlefield Road        NaN   \n",
      "10  11           11         2140 Euclid Avenue.        NaN   \n",
      "11  12           12       1044 Middlefield Road  2nd Floor   \n",
      "12  13           13         399 Marine Parkway.        NaN   \n",
      "13  14           14          660 Veterans Blvd.        NaN   \n",
      "14  15           15        1500 Valencia Street        NaN   \n",
      "15  16           16         1161 South Bernardo        NaN   \n",
      "16  17           17     409 South Spruce Avenue        NaN   \n",
      "17  18           18            114 Fifth Avenue        NaN   \n",
      "18  19           19         19 West 39th Avenue        NaN   \n",
      "19  20           21          123 El Camino Real        NaN   \n",
      "20  21           22  2013 Avenue of the fellows  Suite 100   \n",
      "\n",
      "                   city state_province postal_code country  \n",
      "0          Redwood City             CA       94063      US  \n",
      "1             San Mateo             CA       94401      US  \n",
      "2             San Mateo             CA       94403      US  \n",
      "3             San Mateo             CA       94401      US  \n",
      "4             San Mateo             CA       94401      US  \n",
      "5            Menlo Park             CA  94025-9881      US  \n",
      "6            Menlo Park             CA       94025      US  \n",
      "7            Menlo Park             CA  94025-9881      US  \n",
      "8          Redwood City             CA       94063      US  \n",
      "9          Redwood City             CA       94063      US  \n",
      "10         Redwood City             CA       94061      US  \n",
      "11         Redwood City             CA       94063      US  \n",
      "12         Redwood City             CA       94065      US  \n",
      "13         Redwood City             CA       94063      US  \n",
      "14        San Francisco             CA       94110      US  \n",
      "15            Sunnyvale             CA       94087      US  \n",
      "16  South San Francisco             CA       94080      US  \n",
      "17         Redwood City             CA       94063      US  \n",
      "18            San Mateo             CA       94403      US  \n",
      "19              Belmont             CA       94002      US  \n",
      "20        San Francisco             CA       94103      US  \n"
     ]
    }
   ],
   "source": [
    "result_obj = get_dataframe(file_url=\"https://raw.githubusercontent.com/codeforamerica/ohana-api/refs/heads/master/data/sample-csv/addresses.csv\")\n",
    "print(result_obj.get(\"dataframe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a8a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
